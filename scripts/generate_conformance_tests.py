#!/usr/bin/env python3
"""
Generate MoonBit conformance tests from html5lib-tests suite.

Covers: WHATWG HTML5 Tokenizer and Tree Construction

Uses html5lib (Python) as reference parser.
Test suite: https://github.com/html5lib/html5lib-tests
"""

import json
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

# Paths
SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent
HTML5LIB_TESTS_DIR = PROJECT_DIR / "html5lib-tests"
TOKENIZER_TESTS_DIR = HTML5LIB_TESTS_DIR / "tokenizer"
TREE_TESTS_DIR = HTML5LIB_TESTS_DIR / "tree-construction"
OUTPUT_DIR = PROJECT_DIR / "src" / "conformance_tests"

LICENSE_HEADER = """// ============================================================================
// AUTO-GENERATED FILE - DO NOT MODIFY MANUALLY
// Generated by: scripts/generate_conformance_tests.py
// Regenerate with: python3 scripts/generate_conformance_tests.py
// ============================================================================

// Copyright 2025 International Digital Economy Academy
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

"""


def escape_moonbit_string(s: str) -> str:
    """Escape a string for MoonBit string literal.

    Must match MoonBit's string display format.
    """
    result = []
    for c in s:
        code = ord(c)
        if c == '\\':
            result.append('\\\\')
        elif c == '"':
            result.append('\\"')
        elif c == '\n':
            result.append('\\n')
        elif c == '\t':
            result.append('\\t')
        elif c == '\r':
            # Keep CR in input - tokenizer will normalize it
            result.append('\\r')
        elif code == 0:
            result.append('\\u{0}')
        elif code < 0x20:
            # Short hex format
            result.append(f'\\u{{{code:x}}}')
        elif code == 0x7F:
            result.append('\\u{7f}')
        elif 0x80 <= code <= 0x9F:
            # Short hex format
            result.append(f'\\u{{{code:x}}}')
        elif 0xD800 <= code <= 0xDFFF:
            # Surrogate characters - escape them
            result.append(f'\\u{{{code:x}}}')
        else:
            # All other chars including high Unicode displayed literally
            result.append(c)
    return ''.join(result)


def escape_moonbit_char(c: str) -> str:
    """Escape a single character for MoonBit char literal.

    This must match MoonBit's inspect output format for characters.
    MoonBit uses short hex format without leading zeros (e.g., \\u{81} not \\u{0081}).
    MoonBit displays high Unicode chars (> U+FFFF) literally, not escaped.
    """
    code = ord(c)
    if c == '\\':
        return '\\\\'
    elif c == "'":
        return "\\'"
    elif c == '\n':
        return '\\n'
    elif c == '\t':
        return '\\t'
    elif c == '\r':
        # CR should be normalized to LF by tokenizer
        return '\\n'
    elif code == 0:
        return '\\u{0}'
    elif code < 0x20:
        # Short hex format without leading zeros
        return f'\\u{{{code:x}}}'
    elif code == 0x7F:
        return '\\u{7f}'
    elif 0x80 <= code <= 0x9F:
        # Short hex format without leading zeros
        return f'\\u{{{code:x}}}'
    elif 0xD800 <= code <= 0xDFFF:
        # Surrogates - should be skipped, but escape if present
        return f'\\u{{{code:x}}}'
    # Zero-width and invisible characters (U+200B-U+200F, U+2060-U+206F, U+FEFF)
    elif 0x200B <= code <= 0x200F:
        return f'\\u{{{code:x}}}'
    elif 0x2060 <= code <= 0x206F:
        return f'\\u{{{code:x}}}'
    elif code == 0xFEFF:
        return f'\\u{{{code:x}}}'
    else:
        # MoonBit displays all other characters literally
        return c


def sanitize_test_name(name: str) -> str:
    """Convert test description to valid MoonBit test name."""
    # Remove or replace invalid characters
    name = re.sub(r'[^a-zA-Z0-9_\s]', '', name)
    name = re.sub(r'\s+', '_', name)
    name = name[:50]  # Limit length
    return name.lower()


def clone_html5lib_tests():
    """Clone the html5lib-tests repository if not present."""
    if not HTML5LIB_TESTS_DIR.exists():
        print("Cloning html5lib-tests repository...")
        subprocess.run([
            'git', 'clone', '--depth', '1',
            'https://github.com/html5lib/html5lib-tests.git',
            str(HTML5LIB_TESTS_DIR)
        ], check=True)
        print("Done.")
    else:
        print(f"Using existing html5lib-tests at {HTML5LIB_TESTS_DIR}")


def load_tokenizer_tests() -> List[Dict[str, Any]]:
    """Load all tokenizer test files."""
    tests = []
    if not TOKENIZER_TESTS_DIR.exists():
        print(f"Warning: Tokenizer tests directory not found: {TOKENIZER_TESTS_DIR}")
        return tests

    for test_file in sorted(TOKENIZER_TESTS_DIR.glob("*.test")):
        try:
            with open(test_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for test in data.get('tests', []):
                    test['_file'] = test_file.stem
                    tests.append(test)
        except (json.JSONDecodeError, IOError) as e:
            print(f"  Warning: Failed to load {test_file}: {e}")

    return tests


def decode_html5lib_escapes(s: str) -> str:
    """Decode html5lib test escape sequences like \\uFFFD to actual Unicode."""
    import re
    def replace_escape(m):
        code = int(m.group(1), 16)
        return chr(code)
    return re.sub(r'\\u([0-9A-Fa-f]{4})', replace_escape, s)


def format_expected_tokens(output: List) -> str:
    """Format expected token output for MoonBit."""
    tokens = []
    for item in output:
        if isinstance(item, str):
            if item == "DOCTYPE":
                continue  # Handle separately
            # Character token
            for c in item:
                tokens.append(f"Character('{escape_moonbit_char(c)}')")
        elif isinstance(item, list):
            token_type = item[0]
            if token_type == "DOCTYPE":
                name = item[1] if len(item) > 1 and item[1] else None
                public_id = item[2] if len(item) > 2 and item[2] else None
                system_id = item[3] if len(item) > 3 and item[3] else None
                correctness = item[4] if len(item) > 4 else True

                name_str = f'Some("{escape_moonbit_string(name)}")' if name else 'None'
                pub_str = f'Some("{escape_moonbit_string(public_id)}")' if public_id else 'None'
                sys_str = f'Some("{escape_moonbit_string(system_id)}")' if system_id else 'None'
                quirks = 'true' if not correctness else 'false'
                tokens.append(f'DOCTYPE(name={name_str}, public_id={pub_str}, system_id={sys_str}, force_quirks={quirks})')

            elif token_type == "StartTag":
                name = item[1]
                attrs = item[2] if len(item) > 2 else {}
                self_closing = item[3] if len(item) > 3 else False
                attrs_str = ', '.join(
                    f'{{name: "{escape_moonbit_string(k)}", value: "{escape_moonbit_string(v)}"}}'
                    for k, v in attrs.items()
                )
                tokens.append(f'StartTag(name="{escape_moonbit_string(name)}", attrs=[{attrs_str}], self_closing={str(self_closing).lower()})')

            elif token_type == "EndTag":
                name = item[1]
                tokens.append(f'EndTag(name="{escape_moonbit_string(name)}")')

            elif token_type == "Comment":
                data = item[1] if len(item) > 1 else ""
                data = decode_html5lib_escapes(data)
                tokens.append(f'Comment("{escape_moonbit_string(data)}")')

            elif token_type == "Character":
                data = item[1] if len(item) > 1 else ""
                data = decode_html5lib_escapes(data)
                for c in data:
                    tokens.append(f"Character('{escape_moonbit_char(c)}')")

    tokens.append("EOF")
    return "[" + ", ".join(tokens) + "]"


def generate_tokenizer_test(test: Dict[str, Any], index: int) -> Optional[str]:
    """Generate a single tokenizer test."""
    description = test.get('description', f'test_{index}')
    input_html = test.get('input', '')
    output = test.get('output', [])
    initial_states = test.get('initialStates', ['Data state'])
    double_escaped = test.get('doubleEscaped', False)

    # Skip tests with complex initial states for now
    if initial_states != ['Data state']:
        return None

    # Handle double-escaped input
    if double_escaped:
        try:
            input_html = input_html.encode().decode('unicode_escape')
        except:
            return None

    # Skip tests with null bytes in input (complex handling)
    if '\x00' in input_html and len(input_html) > 100:
        return None

    # Skip tests with surrogate characters (invalid Unicode)
    if any(0xD800 <= ord(c) <= 0xDFFF for c in input_html):
        return None

    safe_name = sanitize_test_name(description)
    file_prefix = test.get('_file', 'unknown')
    test_name = f"html5lib/tokenizer/{file_prefix}_{safe_name}_{index}"

    escaped_input = escape_moonbit_string(input_html)
    expected = format_expected_tokens(output)

    return f'''///|
test "{test_name}" {{
  let (tokens, _) = @html.tokenize("{escaped_input}")
  inspect(tokens, content="{escape_moonbit_string(expected)}")
}}

'''


def generate_tokenizer_tests_files(tests: List[Dict[str, Any]], max_per_file: int = 500) -> List[Tuple[str, str]]:
    """Generate multiple tokenizer conformance test files to avoid OOM."""
    files = []
    current_output = [LICENSE_HEADER]
    current_output.append("///|\n/// html5lib Tokenizer Conformance Tests\n/// Source: https://github.com/html5lib/html5lib-tests\n\n")

    generated = 0
    skipped = 0
    current_count = 0
    file_num = 1

    for i, test in enumerate(tests):
        test_code = generate_tokenizer_test(test, i)
        if test_code:
            current_output.append(test_code)
            generated += 1
            current_count += 1

            if current_count >= max_per_file:
                files.append((f"html5lib_tokenizer_{file_num}_test.mbt", ''.join(current_output)))
                file_num += 1
                current_count = 0
                current_output = [LICENSE_HEADER]
                current_output.append("///|\n/// html5lib Tokenizer Conformance Tests (continued)\n/// Source: https://github.com/html5lib/html5lib-tests\n\n")
        else:
            skipped += 1

    # Write remaining tests
    if current_count > 0:
        files.append((f"html5lib_tokenizer_{file_num}_test.mbt", ''.join(current_output)))

    print(f"  Generated: {generated}, Skipped: {skipped}, Files: {len(files)}")
    return files


def load_tree_construction_tests() -> List[Dict[str, Any]]:
    """Load tree construction tests from .dat files."""
    tests = []
    if not TREE_TESTS_DIR.exists():
        print(f"Warning: Tree construction tests directory not found: {TREE_TESTS_DIR}")
        return tests

    for test_file in sorted(TREE_TESTS_DIR.glob("*.dat")):
        try:
            with open(test_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Parse the .dat format
            current_test = {}
            current_section = None
            current_data = []

            for line in content.split('\n'):
                if line.startswith('#'):
                    # Save previous section
                    if current_section and current_data:
                        current_test[current_section] = '\n'.join(current_data)
                        current_data = []

                    section_name = line[1:].strip()
                    if section_name == 'data':
                        # Start new test
                        if current_test:
                            current_test['_file'] = test_file.stem
                            tests.append(current_test)
                        current_test = {}
                    current_section = section_name
                else:
                    current_data.append(line)

            # Save last section and test
            if current_section and current_data:
                current_test[current_section] = '\n'.join(current_data)
            if current_test:
                current_test['_file'] = test_file.stem
                tests.append(current_test)

        except IOError as e:
            print(f"  Warning: Failed to load {test_file}: {e}")

    return tests


def normalize_expected_tree(tree: str) -> str:
    """Normalize expected tree output for comparison.

    - Strip the '| ' prefix from html5lib-tests format
    - Remove empty lines
    - Ensure consistent formatting
    """
    lines = []
    for line in tree.strip().split('\n'):
        # Keep the line structure but normalize
        if line.strip():
            # Remove the '| ' prefix from html5lib format
            if line.startswith('| '):
                line = line[2:]
            lines.append(line.rstrip())
    return '\n'.join(lines)


def format_multiline_string(s: str) -> str:
    """Format a string as MoonBit multi-line string with #| prefix.

    In #| strings, quotes don't need escaping.
    """
    lines = s.split('\n')
    result_lines = []
    for line in lines:
        # Only escape backslashes and control chars, not quotes
        escaped_line = escape_for_multiline(line)
        result_lines.append(f'      #|{escaped_line}')
    return '\n'.join(result_lines)


def escape_for_multiline(s: str) -> str:
    """Escape a string for MoonBit #| multi-line literal.

    Quotes don't need escaping in #| strings.
    """
    result = []
    for c in s:
        code = ord(c)
        if c == '\\':
            result.append('\\\\')
        elif code == 0:
            result.append('\\u{0}')
        elif code < 0x20 and c not in '\t':
            result.append(f'\\u{{{code:x}}}')
        elif code == 0x7F:
            result.append('\\u{7f}')
        elif 0x80 <= code <= 0x9F:
            result.append(f'\\u{{{code:x}}}')
        else:
            result.append(c)
    return ''.join(result)


def generate_tree_test(test: Dict[str, Any], index: int) -> Optional[str]:
    """Generate a single tree construction test."""
    input_html = test.get('data', '').strip()
    expected_tree = test.get('document', '')
    file_prefix = test.get('_file', 'unknown')

    # Skip if no input or expected output
    if not input_html or not expected_tree:
        return None

    # Skip fragment tests for now
    if 'document-fragment' in test:
        return None

    # Skip scripting tests for now
    if 'script-on' in test or 'script-off' in test:
        return None

    test_name = f"html5lib/tree/{file_prefix}_{index}"
    escaped_input = escape_moonbit_string(input_html)

    # Normalize expected tree and format as multi-line string
    normalized_tree = normalize_expected_tree(expected_tree)
    multiline_content = format_multiline_string(normalized_tree)

    return f'''///|
test "{test_name}" {{
  let doc = @html.parse("{escaped_input}")
  inspect(
    doc.dump(),
    content=(
{multiline_content}
    ),
  )
}}

'''


def generate_tree_tests_files(tests: List[Dict[str, Any]], max_per_file: int = 500) -> List[Tuple[str, str]]:
    """Generate multiple tree construction conformance test files to avoid OOM."""
    files = []
    current_output = [LICENSE_HEADER]
    current_output.append("///|\n/// html5lib Tree Construction Conformance Tests\n/// Source: https://github.com/html5lib/html5lib-tests\n\n")

    generated = 0
    skipped = 0
    current_count = 0
    file_num = 1

    for i, test in enumerate(tests):
        test_code = generate_tree_test(test, i)
        if test_code:
            current_output.append(test_code)
            generated += 1
            current_count += 1

            if current_count >= max_per_file:
                files.append((f"html5lib_tree_{file_num}_test.mbt", ''.join(current_output)))
                file_num += 1
                current_count = 0
                current_output = [LICENSE_HEADER]
                current_output.append("///|\n/// html5lib Tree Construction Conformance Tests (continued)\n/// Source: https://github.com/html5lib/html5lib-tests\n\n")
        else:
            skipped += 1

    # Write remaining tests
    if current_count > 0:
        files.append((f"html5lib_tree_{file_num}_test.mbt", ''.join(current_output)))

    print(f"  Generated: {generated}, Skipped: {skipped}, Files: {len(files)}")
    return files


def main():
    print("Generating HTML5 conformance tests from html5lib-tests...")

    # Clone test suite if needed
    clone_html5lib_tests()

    # Remove old test files
    print("\nRemoving old test files...")
    for old_file in OUTPUT_DIR.glob("html5lib_*.mbt"):
        old_file.unlink()
        print(f"  Removed: {old_file.name}")

    # Generate tokenizer tests
    print("\nPhase 1: Loading tokenizer tests...")
    tokenizer_tests = load_tokenizer_tests()
    print(f"  Found {len(tokenizer_tests)} tokenizer tests")

    print("\nPhase 2: Generating tokenizer test files...")
    tokenizer_files = generate_tokenizer_tests_files(tokenizer_tests, max_per_file=500)
    all_files = []
    for filename, content in tokenizer_files:
        filepath = OUTPUT_DIR / filename
        filepath.write_text(content, encoding='utf-8')
        all_files.append(filepath)
        print(f"  Written: {filename}")

    # Generate tree construction tests
    print("\nPhase 3: Loading tree construction tests...")
    tree_tests = load_tree_construction_tests()
    print(f"  Found {len(tree_tests)} tree construction tests")

    print("\nPhase 4: Generating tree construction test files...")
    tree_files = generate_tree_tests_files(tree_tests, max_per_file=500)
    for filename, content in tree_files:
        filepath = OUTPUT_DIR / filename
        filepath.write_text(content, encoding='utf-8')
        all_files.append(filepath)
        print(f"  Written: {filename}")

    # Format generated files
    print("\nPhase 5: Formatting generated files...")
    for f in all_files:
        try:
            subprocess.run(['moon', 'fmt', str(f)], check=True, capture_output=True)
            print(f"  Formatted: {f.name}")
        except subprocess.CalledProcessError as e:
            print(f"  Warning: moon fmt failed for {f.name}")
        except FileNotFoundError:
            print("  Warning: moon not found, skipping format")
            break

    print("\nDone!")


if __name__ == "__main__":
    main()
